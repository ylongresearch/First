\chapter{Introduction}  %Title of the First Chapter

\section{Learning Visual Attributes} %Section - 1.1 

Vision is an important perceptive approach. Computer vision community has dedicated to improve the visual ability of machines so as to implement high-quality human-machine interaction. My research dedicates to machines to see and to understand. The first challenge is how to make the pixel-level digital information understandable in order to achieve high-level tasks. Thankfully, machine learning community has provided sufficient technical supports. However, as the digital technology is explosively increasing, large-scaled visual information is produced from various types of camera sensors, i.e. photos, films, surveillance, etc. As a result, billions of visual sources in various modalities requires uncountable computing power. The traditional machine learning algorithms tend to become incompetent when dealing with such large-scaled fine-grained learning tasks. Recently, it is proposed that a high-level task can be substituted by several subtasks of learning semantic concepts, which is known as Attribute Learning. Because attributes are human-defined properties that abstracted from the reality, it is not restricted to a certain information source and can help to design generative modal for different modalities based on human requirement. In addition, the knowledge-based visual attributes can be shared among bottom-up tasks. Such properties of attribute learning provides a possible solution to abstract the massive data into semantically understandable representations. \\


%********************************** %Second Section  *************************************
\section{Ontology Engineering in Computer Vision} %Section - 1.2


%********************************** % Third Section  *************************************
\section{Extensive Applications}  %Section - 1.3 



